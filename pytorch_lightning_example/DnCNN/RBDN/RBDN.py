# -*- coding: utf-8 -*-
"""DnCNN_lightning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/SreeHarshaNelaturu/DnCNN-PT-Lightning/blob/master/DnCNN_lightning.ipynb
"""

# !pip install pytorch-lightning

# !nvidia-smi

# !wget https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/BSDS300-images.tgz
# !tar xvzf BSDS300-images.tgz
# !rm BSDS300-images.tgz

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import cv2
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint
import os
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset
import torchvision as tv
from torch.utils.data import DataLoader

from PIL import Image
import matplotlib.pyplot as plt
import time
import random

device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(device)


class NoisyDataset(Dataset):
    def __init__(self, in_path, mode='train', img_size=(128, 128)):
        super(NoisyDataset, self).__init__()

        self.mode = mode  # train or test
        self.in_path = in_path  # ./BSDS300/images
        self.img_size = img_size  # (180, 180)

        self.img_dir = os.path.join(in_path, mode)
        self.imgs = os.listdir(self.img_dir)
        self.sigma = random.randint(8, 50)

    def __len__(self):
        return len(self.imgs)

    def __repr__(self):
        return "Dataset Parameters: mode={}, img_size={}, sigma={}".format(self.mode, self.img_size, self.sigma)

    def __getitem__(self, idx):

        img_path = os.path.join(self.img_dir, self.imgs[idx])
        clean_img = Image.open(img_path).convert('RGB')
        left = np.random.randint(clean_img.size[0] - self.img_size[0])
        top = np.random.randint(clean_img.size[1] - self.img_size[1])
        # .crop(left, upper, right, lower)
        cropped_clean = clean_img.crop(
            [left, top, left+self.img_size[0], top+self.img_size[1]])

        transform = tv.transforms.Compose([tv.transforms.ToTensor(),
                                           tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

        ground_truth = transform(cropped_clean)

        noisy = ground_truth + 2 / 255 * self.sigma * \
            torch.randn(ground_truth.shape)

        return noisy, ground_truth


def dataset_imshow(image, ax=plt):
    image = image.to('cpu').numpy()
    image = np.moveaxis(image, [0, 1, 2], [2, 0, 1])
    image = (image + 1) / 2
    image[image < 0] = 0
    image[image > 1] = 1
    h = ax.imshow(image)
    ax.axis('off')

    return h

# Commented out IPython magic to ensure Python compatibility.
# Start tensorboard.
# %reload_ext tensorboard
# %tensorboard --logdir lightning_logs/


class DnCNN(pl.LightningModule):
    def __init__(self):
        super(DnCNN, self).__init__()

        self.conv_input = nn.Conv2d(
            in_channels=3, out_channels=64, kernel_size=9, padding=4)

        self.conv_middle = nn.Conv2d(
            in_channels=64, out_channels=64, kernel_size=3, padding=1)

        self.conv_concat = nn.Conv2d(
            in_channels=128, out_channels=64, kernel_size=3, padding=1)

        self.pooling_Layer = nn.MaxPool2d(
            kernel_size=2, stride=2, return_indices=True)

        self.unpool_layer = nn.MaxUnpool2d(kernel_size=2, stride=2)

        self.deconv_layer = nn.ConvTranspose2d(
            in_channels=64, out_channels=64, kernel_size=3, padding=1)

        self.deconv_output = nn.ConvTranspose2d(
            in_channels=64, out_channels=3, kernel_size=9, padding=4)

        self.bn_layer = nn.BatchNorm2d(64)

        self.dataset_dir = "/home/mdsamiul/InSAR-Coding/data/BSDS300/images/"

    def forward(self, x):
        conv1 = F.relu(self.bn_layer(self.conv_input(x)))

        pool1, indice1 = self.pooling_Layer(conv1)
        pool1 = F.relu(pool1)

        convB11 = F.relu(self.bn_layer(self.conv_middle(pool1)))

        poolB1, indiceB1 = self.pooling_Layer(convB11)
        poolB1 = F.relu(poolB1)

        convB21 = F.relu(self.bn_layer(self.conv_middle(poolB1)))

        poolB2, indiceB2 = self.pooling_Layer(convB21)
        poolB2 = F.relu(poolB2)

        convB31 = F.relu(self.bn_layer(self.conv_middle(poolB2)))

        poolB3, indiceB3 = self.pooling_Layer(convB31)
        poolB3 = F.relu(poolB3)

        convB32 = F.relu(self.bn_layer(self.conv_middle(poolB3)))

        unpoolB3 = F.relu(self.unpool_layer(convB32, indiceB3))

        deconvB31 = F.relu(self.bn_layer(self.deconv_layer(unpoolB3)))

        concat_poolB2_deconv31 = torch.cat((poolB2, deconvB31), dim=1)

        convB22 = F.relu(self.bn_layer(
            self.conv_concat(concat_poolB2_deconv31)))

        unpoolB2 = F.relu(self.unpool_layer(convB22, indiceB2))

        deconvB21 = F.relu(self.bn_layer(self.deconv_layer(unpoolB2)))

        concat_poolB1_deconvb21 = torch.cat(
            (poolB1, deconvB21), dim=1)

        convB12 = F.relu(self.bn_layer(
            self.conv_concat(concat_poolB1_deconvb21)))

        unpoolB1 = F.relu(self.unpool_layer(convB12, indiceB1))

        deconvB11 = F.relu(self.bn_layer(self.deconv_layer(unpoolB1)))

        concat_pool1_deconvb11 = torch.cat((pool1, deconvB11), dim=1)

        conv21 = F.relu(self.bn_layer(
            self.conv_concat(concat_pool1_deconvb11)))

        conv22 = F.relu(self.bn_layer(self.conv_middle(conv21)))
        conv23 = F.relu(self.bn_layer(self.conv_middle(conv22)))
        conv24 = F.relu(self.bn_layer(self.conv_middle(conv23)))
        conv25 = F.relu(self.bn_layer(self.conv_middle(conv24)))
        conv26 = F.relu(self.bn_layer(self.conv_middle(conv25)))
        conv27 = F.relu(self.bn_layer(self.conv_middle(conv26)))
        conv28 = F.relu(self.bn_layer(self.conv_middle(conv27)))
        conv29 = F.relu(self.bn_layer(self.conv_middle(conv28)))

        unpool1 = F.relu(self.unpool_layer(conv29, indice1))

        deconv1 = F.relu(self.deconv_output(unpool1))

        return deconv1

    def train_dataloader(self):
        return DataLoader(NoisyDataset(self.dataset_dir), batch_size=64)

    def training_step(self, batch, batch_nb):
        x, y = batch
        out = self(x)
        mse = nn.MSELoss()
        loss = mse(y, out)

        tensorboard_logs = {'train_loss': loss}
        return {'loss': loss, 'log': tensorboard_logs}

    def configure_optimizers(self):
        return torch.optim.SGD(self.parameters(), lr=1e-7)


denoising_model = DnCNN()

checkpoint_callback = ModelCheckpoint(dirpath='./checkpoints/',
                                      save_top_k=1,
                                      monitor='train_loss',
                                      verbose=True)


# trainer = pl.Trainer(gpus=1, max_epochs=100000,
#                      checkpoint_callback=checkpoint_callback)

# trainer.fit(denoising_model)

# !ls ./checkpoints/

pretrained_model = DnCNN.load_from_checkpoint(
    "./checkpoints/epoch=98567-step=394271.ckpt")

test_set = NoisyDataset("/home/mdsamiul/InSAR-Coding/data/BSDS300/images",
                        mode='test', img_size=(320, 320))

with torch.no_grad():
    out = pretrained_model(test_set[2][0].unsqueeze(0))

fig, axes = plt.subplots(ncols=2)
dataset_imshow(test_set[2][0], ax=axes[0])
axes[0].set_title('Noisy')
dataset_imshow(out[0], ax=axes[1])
axes[1].set_title('Clean')
print(f'image size is {out[0].shape}.')
plt.savefig(
    "/home/mdsamiul/InSAR-Coding/DnCNN_pytorch_lightning/image/01.jpg", dpi=500)

# train_set = NoisyDataset("/home/mdsamiul/InSAR-Coding/data/BSDS300/images")
# for batch_idx, batch in enumerate(train_set):
#     x, y = batch
#     print(x.shape)
#     break

fig, axes = plt.subplots(ncols=2)
dataset_imshow(test_set[2][0], ax=axes[0])
axes[0].set_title('Noisy')
dataset_imshow(out[0], ax=axes[1])
axes[1].set_title('Clean')
print(f'image size is {out[0].shape}.')
plt.savefig(
    "/home/mdsamiul/InSAR-Coding/DnCNN_pytorch_lightning/image/02.jpg", dpi=500)

# img = cv2.imread('./BSDS300/images/train/104022.jpg')

# dimensions = img.shape

# print(dimensions)
